{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPbuv4pfu_su"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import imutils\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D , BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.morphology import extrema\n",
        "from skimage.morphology import watershed as skwater\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.metrics import confusion_matrix,plot_confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D , BatchNormalization\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from matplotlib import pyplot as plt\n",
        "from skimage.morphology import extrema\n",
        "from skimage.morphology import watershed as skwater\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S1mWPyAvMKz"
      },
      "source": [
        "path1 = '/content/gdrive/My Drive/DATA/INMEYOK/output'\n",
        "path2 = '/content/gdrive/My Drive/DATA/ISKEMI/output'\n",
        "path3 = '/content/gdrive/My Drive/DATA/KANAMA/output'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmKH9eJsvOLy",
        "outputId": "51c1bc78-0fc3-4193-ded0-f0275062c7d2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2_hrJjAvOvy"
      },
      "source": [
        "image_list = []\n",
        "label_list = []\n",
        "def loaddata(path, label):\n",
        "    all_images = os.listdir(path)\n",
        "    i = 0\n",
        "    for image in tqdm(all_images):\n",
        "        img = cv2.imread(os.path.join(path, image))\n",
        "        image_list.append(img)\n",
        "        label_list.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "cD5bJDBavcTC",
        "outputId": "bdeb20f6-ac9c-4f4a-dddb-bdc3e975fb3e"
      },
      "source": [
        "loaddata(path1,0)\n",
        "loaddata(path2,1)\n",
        "loaddata(path3,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1157/1157 [14:38<00:00,  1.32it/s]\n",
            "  7%|▋         | 162/2229 [02:06<26:47,  1.29it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-641792af1722>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mloaddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloaddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloaddata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-744586476e98>\u001b[0m in \u001b[0;36mloaddata\u001b[0;34m(path, label)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mimage_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mlabel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTg4a_2fvjlc"
      },
      "source": [
        "len(image_list)\n",
        "len(label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifle4yDkvorT"
      },
      "source": [
        "img = np.array(image_list)\n",
        "lbl = np.array(label_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaGN59GIvv3q"
      },
      "source": [
        "del image_list\n",
        "del label_list\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV0tJ5MKvz7c"
      },
      "source": [
        "X_train, X_test,y_train, y_test = train_test_split(img,lbl, test_size=0.1,random_state=32, shuffle= True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5REzdCpv3Er"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "num_folds = 6\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rroc5K7Nv6G6"
      },
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16, decode_predictions, preprocess_input\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(240, 240, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9N-llb4Dv6uL"
      },
      "source": [
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False\n",
        "vgg_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3negpPHCwAbM"
      },
      "source": [
        "fold_no = 1\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "for train, test in kfold.split(X_train, y_train):\n",
        "  modelVGG16 = Sequential()\n",
        "  modelVGG16.add(vgg_model)\n",
        "  modelVGG16.add(Flatten())\n",
        "  modelVGG16.add(Dense(1024, activation='relu'))\n",
        "  modelVGG16.add(Dropout(0.2))\n",
        "  modelVGG16.add(Dense(512, activation='relu'))\n",
        "  modelVGG16.add(Dropout(0.2))\n",
        "  modelVGG16.add(Dense(256, activation='relu'))\n",
        "  modelVGG16.add(Dropout(0.2))\n",
        "  modelVGG16.add(Dense(128, activation='relu'))\n",
        "  modelVGG16.add(Dropout(0.2))\n",
        "  modelVGG16.add(Dense(64, activation='relu'))\n",
        "  modelVGG16.add(Dropout(0.2))\n",
        "  modelVGG16.add(Dense(32, activation='relu'))\n",
        "  modelVGG16.add(Dropout(0.2))\n",
        "  modelVGG16.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile model \n",
        "  modelVGG16.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',\n",
        "                                                                          tf.keras.metrics.Precision(),\n",
        "                                                                          tf.keras.metrics.Recall(),\n",
        "                                                                          tf.keras.metrics.AUC(from_logits=True)])\n",
        "   # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  history = modelVGG16.fit(X_train[train], y_train[train], validation_split=0.1,batch_size=10, epochs=10)\n",
        "   # Generate generalization metrics\n",
        "  scores = modelVGG16.evaluate(X_train[test], y_train[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {modelVGG16.metrics_names[0]} of {scores[0]}; {modelVGG16.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArlklU-u51pK"
      },
      "source": [
        "modelVGG16.save_weights('/content/gdrive/My Drive/VGG16')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}